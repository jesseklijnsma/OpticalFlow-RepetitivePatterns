{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from mmeval import EndPointError\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import NoNorm\n",
    "from collections import defaultdict\n",
    "\n",
    "from common.kitti import load_kitti_flow\n",
    "from common.blur import masked_blur\n",
    "from common.metrics import reconstruction_error\n",
    "\n",
    "import common.warp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(common)\n",
    "\n",
    "from common.warp import *\n",
    "from common.blur import *\n",
    "from common.metrics import *\n",
    "\n",
    "\n",
    "def collect_sources(kitti_path: str):\n",
    "    gt_map: dict[int, tuple[np.ndarray, np.ndarray]] = {}\n",
    "    frame_map: dict[int, tuple[np.ndarray, np.ndarray]] = {}\n",
    "    annotation_map: dict[int, list[tuple[tuple[int,int],tuple[int,int]]]] = {}\n",
    "\n",
    "    files = os.listdir(os.path.join(kitti_path, \"flow_occ\"))\n",
    "    pattern=re.compile(r'^(\\d{6})_10\\.png$')\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            index = int(match.group(1))\n",
    "\n",
    "            gt_flow, gt_valid = load_kitti_flow(os.path.join(kitti_path, \"flow_occ\", filename))\n",
    "            gt_map[index] = (gt_flow, gt_valid)\n",
    "\n",
    "    frames: dict[int, dict[int, np.ndarray]] = {}\n",
    "\n",
    "    files = os.listdir(os.path.join(kitti_path, \"image_2\"))\n",
    "    pattern=re.compile(r'^(\\d{6})_(\\d{2})\\.png$')\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            index = int(match.group(1))\n",
    "            frame_number = int(match.group(2))\n",
    "            \n",
    "            frame = cv2.imread(os.path.join(kitti_path, \"image_2\", filename))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            framedict = frames.get(index)\n",
    "            if not framedict:\n",
    "                framedict = {}\n",
    "            framedict[frame_number] = frame\n",
    "            frames[index] = framedict\n",
    "            \n",
    "    for index, framedict in frames.items():\n",
    "        frame_10 = framedict[10]\n",
    "        frame_11 = framedict[11]\n",
    "        \n",
    "        if frame_10 is None or frame_11 is None:\n",
    "            print('Error')\n",
    "            continue\n",
    "            \n",
    "        frame_map[index] = (frame_10, frame_11)\n",
    "        \n",
    "    files = os.listdir(os.path.join(kitti_path, \"raw_annotations\"))\n",
    "    pattern=re.compile(r'^(\\d{6})\\.pkl$')\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            index = int(match.group(1))\n",
    "            \n",
    "            with open(os.path.join(kitti_path, \"raw_annotations\", filename), 'rb') as f:\n",
    "                annotation = pickle.load(f)\n",
    "                annotation_map[index] = annotation['convex_hull_annotations']\n",
    "            \n",
    "    return gt_map, frame_map, annotation_map\n",
    "\n",
    "def batch_eval(\n",
    "    gt_map: dict[int, tuple[np.ndarray, np.ndarray]],\n",
    "    frame_map: dict[int, tuple[np.ndarray, np.ndarray]],\n",
    "    annotation_map: dict[int, list[tuple[tuple[int,int],tuple[int,int]]]],\n",
    "    ):\n",
    "    model_metrics = defaultdict(lambda: {\"epe\": [], \"recon\": []})\n",
    "\n",
    "    kmap = {}\n",
    "\n",
    "    recons = []\n",
    "    \n",
    "    gt_map = {k:v for k,v in gt_map.items() if k == 34}\n",
    "    \n",
    "    for index, (flow_uv, flow_valid) in gt_map.items():\n",
    "        \n",
    "        frame_10, frame_11 = frame_map.get(index)\n",
    "        if frame_10 is None or frame_11 is None:\n",
    "            print(f\"Could not find frame of index {index}\")\n",
    "            continue\n",
    "        \n",
    "        isdense = np.count_nonzero(flow_valid) > 100\n",
    "    \n",
    "        # frame_10 = cv2.blur(frame_10, (k,k))\n",
    "        pred_frame_11, pred_valid = forward_warp_bilinear(frame_10, flow_uv, flow_valid)\n",
    "        # pred_frame_11, pred_valid = forward_displacement_interpolation(frame_10, flow_uv, flow_valid)\n",
    "        \n",
    "        for k in range(1,21,2):\n",
    "            err=reconstruction_error(masked_blur(frame_11, pred_valid, k), masked_blur(pred_frame_11, pred_valid, k), pred_valid)\n",
    "\n",
    "            l = kmap.get(k,[])\n",
    "            l.append(err)\n",
    "            kmap[k] = l\n",
    "        \n",
    "                \n",
    "        \n",
    "        error = reconstruction_error(frame_11, pred_frame_11, pred_valid) \n",
    "        \n",
    "        if isdense and index in annotation_map:\n",
    "            p1, p2 = np.array(list(zip(*annotation_map[index])))\n",
    "            # annotation_error = np.mean(np.linalg.norm(frame_10[p1[:,1],p1[:,0]] - frame_11[p2[:,1],p2[:,0]], axis=1))\n",
    "            annotation_error = reconstruction_error(frame_10[p1[:,1],p1[:,0]],frame_11[p2[:,1],p2[:,0]])\n",
    "            print(index, \"Dense  error:\", error, \"Annotation error:\",annotation_error)  \n",
    "            \n",
    "            recons.append(annotation_error)\n",
    "        else:\n",
    "            print(index, \"Sparse error:\", error)  \n",
    "            recons.append(error) \n",
    "    \n",
    "    print(\"Annotation error per blur kernel size:\", {k:np.mean(v) for k,v in kmap.items()})\n",
    "            \n",
    "    k=3\n",
    "    \n",
    "    print(f\"Using blur with kernel size {k}\")\n",
    "    frame_11 = cv2.blur(frame_11, (k,k))\n",
    "    pred_frame_11 = cv2.blur(pred_frame_11, (k,k))\n",
    "    \n",
    "\n",
    "    print(\"Mean image error\", reconstruction_error(frame_11, np.zeros_like(frame_11)))\n",
    "    \n",
    "    vis_image = np.linalg.norm(frame_11.astype(np.float32) - pred_frame_11.astype(np.float32), axis=2)\n",
    "    # vis_image = np.abs(frame_11 - pred_frame_11)\n",
    "    \n",
    "    plt.title('Actual second frame')\n",
    "    plt.imshow(frame_11, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title('Forward flowed second frame based on ground-truth flow vectors')\n",
    "    plt.imshow(pred_frame_11, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title('Euclidean distance on colors')\n",
    "    plt.imshow(vis_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "        \n",
    "    vis_image = cv2.addWeighted(frame_11,0.5,pred_frame_11,0.5,0)\n",
    "    plt.title('Actual second frame and forward flowed second frame overlayed')\n",
    "    plt.imshow(vis_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "        \n",
    "    print(np.mean(recons))\n",
    "\n",
    "    return model_metrics\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kitti_path = r\"./data_kitti\"\n",
    "    \n",
    "    gt_map, frame_map, annotation_map = collect_sources(kitti_path)\n",
    "    \n",
    "    metrics = batch_eval(gt_map, frame_map, annotation_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
