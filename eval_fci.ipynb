{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from mmeval import EndPointError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from common.kitti import load_kitti_flow\n",
    "from common.warp import forward_warp_bilinear\n",
    "from common.metrics import reconstruction_error\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sources(kitti_path: str, pred_path: str):\n",
    "    gt_map: dict[int, tuple[np.ndarray, np.ndarray]] = {}\n",
    "    frame_map: dict[int, tuple[np.ndarray, np.ndarray]] = {}\n",
    "    pred_map: dict[str, dict[int, str]] = {} # grouped by model name, then by index. Stores filenames\n",
    "\n",
    "    files = os.listdir(os.path.join(kitti_path, \"flow_occ\"))\n",
    "    pattern=re.compile(r'^(\\d{6})_10\\.png$')\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            index = int(match.group(1))\n",
    "\n",
    "            gt_flow, gt_valid = load_kitti_flow(os.path.join(kitti_path, \"flow_occ\", filename))\n",
    "            gt_map[index] = (gt_flow, gt_valid)\n",
    "\n",
    "    frames: dict[int, dict[int, np.ndarray]] = {}\n",
    "\n",
    "    files = os.listdir(os.path.join(kitti_path, \"image_2\"))\n",
    "    pattern=re.compile(r'^(\\d{6})_(\\d{2})\\.png$')\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            index = int(match.group(1))\n",
    "            frame_number = int(match.group(2))\n",
    "            \n",
    "            frame = cv2.imread(os.path.join(kitti_path, \"image_2\", filename))\n",
    "            \n",
    "            framedict = frames.get(index)\n",
    "            if not framedict:\n",
    "                framedict = {}\n",
    "            framedict[frame_number] = frame\n",
    "            frames[index] = framedict\n",
    "            \n",
    "    for index, framedict in frames.items():\n",
    "        frame_10 = framedict[10]\n",
    "        frame_11 = framedict[11]\n",
    "        \n",
    "        if frame_10 is None or frame_11 is None:\n",
    "            print('Error')\n",
    "            continue\n",
    "            \n",
    "        frame_map[index] = (frame_10, frame_11)\n",
    "\n",
    "    files = os.listdir(pred_path)\n",
    "    pattern = re.compile(r'^(.*)-(\\d{7})\\.png$')\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            index = int(match.group(2))\n",
    "            model_name = match.group(1)\n",
    "\n",
    "            if model_name not in pred_map:\n",
    "                pred_map[model_name] = {}\n",
    "\n",
    "            pred_map[model_name][index] = os.path.join(pred_path, filename)\n",
    "            \n",
    "    return gt_map, frame_map, pred_map\n",
    "\n",
    "   \n",
    "def plot_mean_scatter(model_metrics, reference, labels=None):\n",
    "    means = [(model, np.mean(vals[\"epe\"]), np.mean(vals[\"recon\"])) for model, vals in model_metrics.items()]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for model, mean_epe, mean_recon in means:\n",
    "        ax.scatter(mean_epe, mean_recon, s=30)\n",
    "        if not labels or model in labels:\n",
    "            ax.annotate(model, xy=(mean_epe, mean_recon), fontsize=9, xytext=(5,-5),  textcoords=\"offset points\")\n",
    "\n",
    "    ax.axhline(reference, color='r', linestyle='--', linewidth=1, label='Reference Line')\n",
    "\n",
    "    ax.set_xlabel(\"Mean EPE\")\n",
    "    ax.set_ylabel(\"Mean Reconstruction Error\")\n",
    "    ax.set_title(\"Mean EPE vs. Mean Reconstruction Error per Model\")\n",
    "    \n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_per_sample_scatter(model_metrics):\n",
    "    fig, axs = plt.subplots(len(model_metrics), 1, figsize=(6, 4 * len(model_metrics)))\n",
    "    \n",
    "    if len(model_metrics) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for ax, (model, vals) in zip(axs, model_metrics.items()):\n",
    "        ax.scatter(vals[\"epe\"], vals[\"recon\"])\n",
    "        ax.set_title(f\"{model}: EPE vs Recon Error\")\n",
    "        ax.set_xlabel(\"EPE\")\n",
    "        ax.set_ylabel(\"Reconstruction Error\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def batch_eval(\n",
    "    gt_map: dict[int, tuple[np.ndarray, np.ndarray]],\n",
    "    frame_map: dict[int, tuple[np.ndarray, np.ndarray]],\n",
    "    pred_map: dict[str, dict[int, str]],\n",
    "    warp_output_dir: str,\n",
    "    save_warps: bool,\n",
    "    load_warps: bool,\n",
    "    use_mask: bool\n",
    "    ):\n",
    "    \n",
    "    os.makedirs(warp_output_dir, exist_ok=True)\n",
    "    \n",
    "    model_metrics = defaultdict(lambda: defaultdict(lambda: {\"epe\": [], \"recon\": []}))\n",
    "\n",
    "    for index, (flow_uv, flow_valid) in tqdm(gt_map.items()):\n",
    "        frame_10, frame_11 = frame_map.get(index)\n",
    "        if frame_10 is None or frame_11 is None:\n",
    "            print(f\"Could not find frame of index {index}\")\n",
    "            continue\n",
    "        \n",
    "        for model_name, path_map in pred_map.items():\n",
    "            pred_path = path_map.get(index)\n",
    "            if not pred_path:\n",
    "                print(\"Error pred path:\", pred_path, model_name, index)\n",
    "                continue\n",
    "            \n",
    "            warp_output_path = os.path.join(warp_output_dir, f\"warp_{os.path.basename(pred_path)}\")\n",
    "            warp_present = os.path.exists(warp_output_path)\n",
    "            \n",
    "            pred_flow_uv, pred_flow_valid = load_kitti_flow(pred_path)\n",
    "            if load_warps and warp_present:\n",
    "                pred_frame_11 = cv2.imread(warp_output_path)\n",
    "            else:\n",
    "                pred_frame_11, pred_valid = forward_warp_bilinear(frame_10, pred_flow_uv)\n",
    "            \n",
    "            if (not load_warps or not warp_present) and save_warps:\n",
    "                cv2.imwrite(warp_output_path, pred_frame_11)\n",
    "                \n",
    "            if frame_10.shape != pred_frame_11.shape:\n",
    "                print(f\"Error\")\n",
    "                continue\n",
    "            \n",
    "            for k in range(1,21,2):\n",
    "                blur_frame_11 = cv2.blur(frame_11, (k,k))\n",
    "                blur_pred_frame_11 = cv2.blur(pred_frame_11, (k,k))\n",
    "                \n",
    "                recon_error = reconstruction_error(blur_frame_11, blur_pred_frame_11, flow_valid if use_mask else None)\n",
    "                epe = EndPointError()([pred_flow_uv], [flow_uv], [flow_valid])['EPE'][0]\n",
    "                    \n",
    "                model_metrics[k][model_name][\"epe\"].append(epe)\n",
    "                model_metrics[k][model_name][\"recon\"].append(recon_error)\n",
    "            \n",
    "    return model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_path = r\"./data_kitti\"\n",
    "pred_path = r\"./results/inference\"\n",
    "\n",
    "warp_output_path = r\"./results/warp\"\n",
    "\n",
    "save_warps = True\n",
    "load_warps = True\n",
    "use_mask = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "gt_map, frame_map, pred_map = collect_sources(kitti_path, pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics_list = batch_eval(gt_map, frame_map, pred_map, warp_output_path, save_warps, load_warps, use_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set blur kernel size.\n",
    "k = 3\n",
    "metrics = metrics_list[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all\n",
    "plot_mean_scatter(metrics, 10.184816)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single model\n",
    "plot_per_sample_scatter({'sea_raft_m_kitti':metrics['sea_raft_m_kitti']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove seperation by training checkpoint. Will take the mean of all samples over all checkpoint.\n",
    "metrics_agg = {}\n",
    "for model_name, valuesdict in metrics.items():\n",
    "    model_name = model_name.rpartition('_')[0] # Remove training checkpoint from model name\n",
    "    newvdict = metrics_agg.get(model_name, {})\n",
    "    for metric, values in valuesdict.items():\n",
    "        vs = newvdict.get(metric, [])\n",
    "        vs += values\n",
    "        newvdict[metric] = vs\n",
    "    metrics_agg[model_name] = newvdict\n",
    "\n",
    "# Only label interesting models\n",
    "labels = [\n",
    "    'ms_raft_p',\n",
    "    'ccmr_p',\n",
    "    'ccmr',\n",
    "    'liteflownet3s',\n",
    "    'sea_raft_l',\n",
    "    'gma',\n",
    "    'llaflow',\n",
    "    'liteflownet',\n",
    "    'flowformer',\n",
    "    'raft',\n",
    "    'sea_raft_m',\n",
    "    'memflow_t',\n",
    "    'dpflow',\n",
    "]\n",
    "\n",
    "plot_mean_scatter(metrics_agg, 10.184816, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k:sanitize(v) for k,v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [sanitize(x) for x in obj]\n",
    "    if isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    return obj\n",
    "\n",
    "raw_data = sanitize(metrics_list)\n",
    "\n",
    "import pickle\n",
    "with open('./results/data/fci_evaluation.pkl', 'wb') as f:\n",
    "    pickle.dump(raw_data, f)\n",
    "    \n",
    "import json\n",
    "with open('./results/data/fci_evaluation.json', 'w') as f:\n",
    "    json.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[1]['ccmr_kitti']['epe'][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
